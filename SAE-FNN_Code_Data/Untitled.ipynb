{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.core._multiarray_umath'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy.core._multiarray_umath'"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<class '_frozen_importlib._ModuleLockManager'> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: <class '_frozen_importlib._ModuleLockManager'> returned a result with an error set"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core._multiarray_umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core._multiarray_umath failed to import"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.umath failed to import"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential, save_model, load_model\n",
    "from keras.callbacks import CSVLogger,ModelCheckpoint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import six.moves.cPickle as pickle\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import matplotlib.ticker as ticker\n",
    "from keras.layers.advanced_activations import LeakyReLU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-e8e6f09789a0>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-e8e6f09789a0>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    python ! pip install --upgrade pip\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    " pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################\n",
    "#Parameters\n",
    "###########################################################################################################\n",
    "encoding_dim = 10                                                 #deep spectral feature dimension.  5,10,20,30,40,50,60,70,80,90 were used in paper\n",
    "input_dim = 512                                                   #input orginal pixel spectral band number\n",
    "batch_size = 100                                                  #learning batch of model\n",
    "nb_epoch = 100                                                    #learning epoch of model\n",
    "SAEmodelpath=\"logs/SAEs_model\"                                    #save SAE model file path\n",
    "SAEmodelweightpath=\"logs/SAEs_model.weights.hdf5\"                 #save SAE weight file path\n",
    "SAEmodeltrainlogpath=\"logs/SAEs_model.train.log\"                  #train log file path\n",
    "FNNmodelpath=\"logs/trained_SAE-FNNmodels/SAE-FNN10/FNN_model\"     #save SAE-FNN model file path\n",
    "FNNmodelweightpath=\"logs/trained_SAE-FNNmodels/SAE-FNN10/FNN_model.weights.hdf5\" #save SAE-FNN model weights file path\n",
    "FNNmodeltrainlogpath=\"logs/FNNmodel.train.log\"                    #train log file path\n",
    "train_dataset=\"data/train_pixels/ramdonpixel_train.pkl.gz\"        #train dataset \n",
    "validation_dataset=\"data/train_pixels/ramdonpixel_val.pkl.gz\"     #validation dataset\n",
    "meanspectrumdataset=\"data/Meanspectra.csv\"                        #Mean spectra for each sample in both calibration and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################\n",
    "#Load data.\n",
    "###########################################################################################################\n",
    "with gzip.open(train_dataset, 'rb') as f:\n",
    "            train_set1, valid_set1 = pickle.load(f)\n",
    "with gzip.open(validation_dataset, 'rb') as f:\n",
    "            train_set2, valid_set2= pickle.load(f)\n",
    "x_train=train_set1[0]  #orginal 51,264 pixel spectra with 512 bands\n",
    "x_valid=train_set2[0]  #orginal 51,264 pixel spectra with 512 bands\n",
    "y_train=train_set1[1]  # N content label of spectra\n",
    "y_valid=train_set2[1]  # N content label of spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###########################################################################################################\n",
    "#Build a SAE model with 512-220-100-encoding_dim-100-220-512\n",
    "###########################################################################################################\n",
    "SAEsmodel = Sequential()\n",
    "SAEsmodel.add(Dense(220, input_dim=input_dim, kernel_initializer='normal', name=\"dense_1\")) #encodeing layer\n",
    "SAEsmodel.add(LeakyReLU())                                                                      #add active function\n",
    "SAEsmodel.add(Dense(100, kernel_initializer='normal', name=\"dense_2\"))                      #encodeing layer\n",
    "SAEsmodel.add(LeakyReLU())                                                                      #add active function\n",
    "SAEsmodel.add(Dense(encoding_dim, kernel_initializer='normal', name=\"dense_3\"))             #this is the deep feature layer\n",
    "SAEsmodel.add(LeakyReLU())                                                                      #add active function\n",
    "SAEsmodel.add(Dense(100, kernel_initializer='normal', name=\"dense_4\"))                      #deconding layer\n",
    "SAEsmodel.add(LeakyReLU())                                                                      #add active function\n",
    "SAEsmodel.add(Dense(220, kernel_initializer='normal', name=\"dense_5\"))                      #deconding layer\n",
    "SAEsmodel.add(LeakyReLU())                                                                      #add active function\n",
    "SAEsmodel.add(Dense(input_dim, kernel_initializer='normal',name=\"dense_6\"))                 #deconding layer\n",
    "SAEsmodel.add(LeakyReLU())                                                                      #add active function\n",
    "\n",
    "#Pre-train SAE model\n",
    "save_model(SAEsmodel,SAEmodelpath)                                       #Save model\n",
    "checkpoint = ModelCheckpoint(filepath=SAEmodelweightpath, verbose=0)     #Save weights\n",
    "csv_logger = CSVLogger(SAEmodeltrainlogpath,separator=',', append=False) #Save train history\n",
    "SAEsmodel.compile(optimizer='Adam', loss='mean_squared_error')           #loss function MSE, optimizer adam\n",
    "SAEsmodel.summary() #Show SAEs model struction\n",
    "\n",
    "#Training\n",
    "history = SAEsmodel.fit(x_train, x_train,\n",
    "                nb_epoch=nb_epoch,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_valid, x_valid),\n",
    "                callbacks=[checkpoint,csv_logger])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################\n",
    "#After pre-training SAE, we build SAE-FNN model:512-220-100-encoding_dim-1\n",
    "###########################################################################################################\n",
    "###########################################################################################################\n",
    "#Rebuild SAE model without decoding layers. \n",
    "SAEs_FNNmodel = Sequential()\n",
    "SAEs_FNNmodel.add(Dense(220, input_dim=input_dim, kernel_initializer='normal', name=\"dense_1\"))   \n",
    "SAEs_FNNmodel.add(LeakyReLU())\n",
    "SAEs_FNNmodel.add(Dense(100, kernel_initializer='normal', name=\"dense_2\"))\n",
    "SAEs_FNNmodel.add(LeakyReLU())\n",
    "SAEs_FNNmodel.add(Dense(encoding_dim, kernel_initializer='normal', name=\"dense_3\")) #this is the deep feature layer\n",
    "SAEs_FNNmodel.add(LeakyReLU())\n",
    "\n",
    "#Add a 1 output fully-connected layer to the encoding layer of SAE without active function\n",
    "SAEs_FNNmodel.add(Dense(1, kernel_initializer='normal', name=\"FNNlayer\"))\n",
    "\n",
    "#Restore the trained SAE model weights.The learned weights of SAE model will be used as initial weights for SAE-FNN\n",
    "SAEs_FNNmodel.load_weights(SAEmodelweightpath,by_name=True) \n",
    "\n",
    "#build SAE-FNN model \n",
    "save_model(SAEs_FNNmodel,FNNmodelpath)\n",
    "SAEs_FNNmodel.compile(optimizer='Adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#save SAE-FNN model weights                                                        \n",
    "checkpoint = ModelCheckpoint(filepath=FNNmodelweightpath, verbose=0)\n",
    "csv_logger = CSVLogger(FNNmodeltrainlogpath,separator=',', append=False) #Save train history                     \n",
    "SAEs_FNNmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dataset.\n",
    "###########################################################################################################\n",
    "Meanspectrums = pd.read_csv(meanspectrumdataset,header=0)\n",
    "x=np.array(Meanspectrums)[:,3:515]   #512 bands of mean spectra\n",
    "y=np.array(Meanspectrums)[:,2:3]     # N content label\n",
    "\n",
    "#Divided into calibration and testing set\n",
    "calibration_x=x[np.where(np.array(Meanspectrums)[:,1] == 1)] # Get 128 calibration_x, dataset value=1\n",
    "calibration_y=y[np.where(np.array(Meanspectrums)[:,1] == 1)] # Get calibration_y , dataset value=1\n",
    "\n",
    "#fine-tune the SAE-FNN model\n",
    "history = SAEs_FNNmodel.fit(calibration_x, calibration_y,\n",
    "                nb_epoch=11000,\n",
    "                batch_size=100,\n",
    "                shuffle=True,\n",
    "                validation_data=(calibration_x, calibration_y),\n",
    "                callbacks=[csv_logger])\n",
    "loss, accuracy = SAEs_FNNmodel.evaluate(calibration_x, calibration_y)\n",
    "print(\"finished training of SAE-FNN model, please use SAE-FNNpredict file to get prediction results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
