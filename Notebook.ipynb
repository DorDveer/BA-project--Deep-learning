{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Deep Learning Meets Hyperspectral Image Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ABSTRACT\n",
    "For our deep learning project, we present the recreation of one algorithm from the paper “Deep-learning-based regression model and hyperspectral imaging for rapid detection of nitrogen concentration in oilseed rape” (Brassica napus L.) leaf. https://www.sciencedirect.com/science/article/pii/S0169743917306780#ec-research-data\n",
    "\n",
    "We will present:\n",
    "- First, a recreation of SAE-FNN model.\n",
    "- Next, a recreation of SAE-FNN hyperparameters optimization. \n",
    "- Finally, a predication of nitrogen concentration compared to results in the paper. \n",
    "\n",
    "In order to gain additional computing resources, we extended the experiments to Amazon Web Services Elastic Compute Cloud (EC2).\n",
    "\n",
    "An in-depth discussion of our recreation and additional experiments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL ARCHITECTURE\n",
    "\n",
    "The model has two phases:\n",
    "\n",
    "##### 1. SAE\n",
    "- The sequential model is a linear stack of layers.\n",
    "- We created a sequential model by calling the keras_model_sequential() function and then a series of layer functions.\n",
    "- Keras objects are modified particularly in place, therefore it is not necessary for the model to be assigned back after the layers have been are added.\n",
    "- Therefore, we can claim that SAE represent unsupervised learning. The learning is from the added layers. \n",
    "- The model needs to know what input shape (input_shape ) it should expect. For this reason, the first layer in a sequential model (and only the first, because following layers can do automatic shape inference) needs to receive information about its input shape..\n",
    "- Before training a model, we need to configure the learning process, which is done via the compile() function, that included three arguments:\n",
    "    1. An optimizer. \n",
    "    2. A loss function.\n",
    "    3. A list of metrics.\n",
    "    \n",
    "\n",
    "Notation as mentioned in the paper:\n",
    "\n",
    "- Input and output layer of $d$ units (=input_shape).\n",
    "- Hidden layer of $h$ units.\n",
    "- Activation function- f() (=ADAM, MSE and relu/elu)\n",
    "- First the algorithm maps the input $ x\\in R^{d}$ to the hidden layer and produces the latent activity $ y\\in R^{h}$ which is called \"encoding\".\n",
    "- Then $y$ is mapped back to an output layer that has the same size of the input layer, which is calles \"decoding\".\n",
    "- The reconstructed values are denoted as $ z\\in R^{d}$.\n",
    "- These to stepd can be formulated as:\n",
    "\n",
    "$ y=f(w_{y}x+b_{y}),$\n",
    "$ z=f(w_{z}y+b_{z})$\n",
    "   \n",
    "  \n",
    "- Where $w_{y}$ is the input-to-hidden weight matrix.\n",
    "- $w_{z}$ is the hidden-to-output weight matrix.\n",
    "- $b_{y}$ and $b_{z}$ denote the bias of hidden and output units.\n",
    "- The goal of learning is to minimize the \"error\" between input and output, which are denoted as: $argmin_{W,b_{y},b_{z}}[c(x,z)]$ where $ w_{y}={w}'_{z}=W$\n",
    "\n",
    "##### 2. FNN\n",
    "- We used SAE to extract deep spectral features from hyperspectral image, and then these features were used as input data for FNN to predict N concentration.\n",
    "- Therefore, we can claim that FNN represent supervised learning. \n",
    "- Keras models are trained on R matrices or higher dimensional arrays of input data and labels. For training a model, we will use the fit() function.\n",
    "- For FNN no activation function is used for the output layer of FNN network because it is a regression problem.\n",
    "- Output of FNN is a single unit denoted as (Notation as mentioned in the paper): \n",
    " $\\hat{y}=w_{l}y_{l}+b_{l}$\n",
    "- $\\hat{y}$ is the output numerical value.\n",
    "- $w_{l}$ is the weight matrix.\n",
    "- $b_{l}$ is the bias of output unit.\n",
    "- $y_{l}$ is the outputsof the last encoding layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "img=mpimg.imread('2.jpg')\n",
    "plt.imshow(img)\n",
    "im = Image.open(\"2.jpg\")\n",
    "im.rotate(45).show()\n",
    "plt.axis('off')\n",
    "plt.show(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the fig above:\n",
    "\n",
    "$1, x_{1},x_{2},...,x_{m}$ - Inputs layers.\n",
    "\n",
    "$w_{0},w_{1},...,w_{m}$- Weight matrix.\n",
    "\n",
    "Activation function- Relu/elu.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  INTRODUCTION\n",
    "The authors of the paper present several algorithms that generate predictions for nitrogen concentration in oilseed rape leaf: PLS, LS-SVM, SAE- FNN (with different units of last layer). The SAE-FNN algorithm works by first training and tuning a neural network using specific hyperparameters and fine tuning, evaluated over a test dataset. In the paper, the authors test the algorithm against several other algorithms, including PLS and LS-SVM, and compare the performance of with these algorithms across multiple different SAE-FNN models which depends on last layer values. In this report, we examine and attempt to recreate several of the results given in the paper. We focus on one particular result, that SEA-FNN10 achieved better results than those yielded by PLS, LS-SVM and other SEA-FNN models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVERVIEW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RECREATION GOALS\n",
    "Our recreate of SAE- FNN10 targets following objectives. Firstly, to recreate the results of the paper, in which the authors found that SAE-FNN10 outperformed other models. Secondary, we hope to learn more about the results. Finally, we want to learn about using EC2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  RECREATION SETUPS\n",
    "\n",
    "In order to recreate the paper results and extend our knowledge, the recreation setup used a Jupyter notebook based EC2 Instance type t2.xlarge with Ubuntu environment.\n",
    "\n",
    "Our recreation is based on code provided by the authors of the paper, which can be found at https://www.sciencedirect.com/science/article/abs/pii/S0169743917306780#ec-research-data. Notably, that authors did not provide any code to optimization and tuning. Therefore, we wrote scripts in order to optimize and tune SAE-FNN based on the information provided in the paper. As a result, we had to modify the code to allow us faithfully reproduce the results in the paper. Our changes to the original code are below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA DESCRIPTION \n",
    "For each sample-nitrogen concentration, spectral data in the range of 380–1030 nm wavelength with 512 bands of each pixel were taken. As mentioned before, we modified the base code and the data in order to perform hyperparameter tuning. Therefore, we combined validation and train set into one data set. The next step was to split the train (80%) and test sets (20%). Tuning parameters performed with Talos package, therefore, we didn't use validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow\n",
    "1. Import libraries.\n",
    "2. Data loading and splitting.\n",
    "3. Data visualization.\n",
    "4. Keras sequential Model defintion.\n",
    "5. Hyperparameters optimization.    \n",
    "6. Prediction.\n",
    "7. Summary and conclusion.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Core libraries for data processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.core.umath_tests import inner1d\n",
    "import pandas as pd\n",
    "from pandas.core import datetools\n",
    "import gzip\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import six.moves.cPickle as pickle\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from numpy import sqrt\n",
    "import random\n",
    "random.seed(100) # for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keras items\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras.activations import relu, elu\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.layers import Input, Dense,Dropout\n",
    "from keras.models import Model, Sequential, save_model, load_model\n",
    "from keras.callbacks import CSVLogger,ModelCheckpoint\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import talos as ta\n",
    "from talos.metrics.keras_metrics import fmeasure_acc\n",
    "from talos import live\n",
    "from talos.utils.gpu_utils import multi_gpu\n",
    "from talos.utils.gpu_utils import force_cpu\n",
    "sys.path.insert(0, '/home/ubuntu/talos/')\n",
    "import wrangle as wr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  DATA LOADING\n",
    "For each sample-nitrogen concentration, spectral data in the range of 380–1030 nm wavelength with 512 bands of each pixel were taken. As we mention before we modified the base code and the data in order to perform hyperparameter tuning. Therefore, we combined validation and train set into one data set. The next step was to split to train (80%) and test (20%) sets. Tuning parameters preformed with Talos package, as a result, we didn't use validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset=\"/home/ubuntu/SAE-FNN_Code_Data/data/train_pixels/ramdonpixel_train.pkl.gz\"   #train dataset \n",
    "validation_dataset=\"/home/ubuntu/SAE-FNN_Code_Data/data/train_pixels/ramdonpixel_val.pkl.gz\"#validation dataset        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with gzip.open(train_dataset, 'rb') as f:\n",
    "            train_set1, valid_set1 = pickle.load(f)\n",
    "with gzip.open(validation_dataset, 'rb') as f:\n",
    "            train_set2, valid_set2= pickle.load(f)\n",
    "X=np.concatenate((train_set1[0],train_set2[0],valid_set1[0],valid_set2[0]))# wavelength\n",
    "y=np.concatenate((train_set1[1],train_set2[1],valid_set1[1],valid_set2[1]))# N concetration\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100, shuffle=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/ubuntu/SAE-FNN_Code_Data/data/Meanspectra.csv\") #Mean spectra for each sample \n",
    "y_mean=data.iloc[:, 2]\n",
    "X_mean=data.iloc[:, 3:]\n",
    "band=range(512)\n",
    "# Plot spectra\n",
    "plt.figure(figsize=(15,10))\n",
    "with plt.style.context(('ggplot')):\n",
    "    plt.plot(band, X_mean.T)\n",
    "    plt.xlabel('Band number')\n",
    "    plt.ylabel('Reflectance')    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Notice that region of bands 1-120, have moderate change while in the region of bands 250-512 have drastic change of reflectance.\n",
    " In addition, in region 250- 300 there are significant difference between each band.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  KERAS SEQUENTIAL MODEL \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input: train (70%) and validation (30%) data with grid of paramaters (p)\n",
    "# output: compiled model and model's data\n",
    "def model_opti(x_train, y_train, x_val, y_val, params):\n",
    "    \n",
    "    #model format\n",
    "    model = Sequential()\n",
    "    \n",
    "    #input layer\n",
    "    model.add(Dense(params['first_neuron'],\n",
    "                    input_dim=x_train.shape[1],\n",
    "                    #this line is used to convey the fact that we wish to tune the activation \n",
    "                    #function parameter and find the best fit among \n",
    "                    activation=params['activation'],\n",
    "                    #this line is used to convey the fact that we wish to tune the \n",
    "                    #kernel initializer parameter and find the best fit among \n",
    "                    kernel_initializer=params['kernel_initializer']))  \n",
    "    #adding more layers\n",
    "    #this line is used to convey the fact that we wish to tune the value of the keep probability of \n",
    "    #Dropout and find the best fit among the range of real numbers between 0 and 1.(=0)\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(Dense(1, activation=params['last_activation'],\n",
    "                    kernel_initializer=params['kernel_initializer']))\n",
    "    \n",
    "    #compiling the model\n",
    "    #we declare the loss function and the optimizer\n",
    "    model.compile(loss=params['losses'],\n",
    "                  optimizer=params['optimizer'](),\n",
    "                  metrics=['acc', fmeasure_acc])\n",
    "    \n",
    "    #fitting the model on training data\n",
    "    history = model.fit(x_train, y_train, \n",
    "                        validation_data=[x_val, y_val],\n",
    "                        batch_size=params['batch_size'],\n",
    "                        epochs=params['epochs'],\n",
    "                        verbose=1)\n",
    "\n",
    "\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HYPERPARAMETERS OPTIMIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hidden_layers: Layer between input and output layers, where artificial neurons take in a set of weighted inputs and produce an output through an activation function.\n",
    "- Batch_size: Number of patterns appear on the network before the weight matrix is updated. If the batch size is small, patterns would be less repetitive and hence the weights would be all over the place, making convergence difficult. If batch size is high, learning would become slow as only after many iterations will the batch size change.\n",
    "- Epochs: The number of epochs is the number of times the entire training data is shown to the model. It plays an important role in how well the model fits on the train data. High number of epochs may overfit to the data and may have generalization problems on the test and validation set, also they could cause vanishing and exploding gradient problems.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dropout: The keep-probability of the Dropout layer.\n",
    "- Kernel initializer: Doesn’t play a very significant role, but still preferred to use normal/uniform initialization while using ReLUs/eLUs.\n",
    "- Optimizer: It is the algorithm used by the model to update weights of every layer after each iteration. \n",
    "- Losses: We seek to minimize the error. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to achieve better parameters, we changed the grid range a couple of times.\n",
    "\n",
    "Assumption that was used: the more epochs the better, until reaching overfitting. Hence, we used a small value of epochs in the tuning section, and in the final model we used a larger value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the parameter space\n",
    "p =  {'first_neuron':[7,8,9,10,20],\n",
    "     'hidden_layers':[3,4,5,10],\n",
    "     'batch_size': [128],\n",
    "     'epochs': [20],\n",
    "     'dropout': [0.5,0.6,0.7,0.8],\n",
    "     'kernel_initializer': ['normal','uniform'],\n",
    "     'optimizer': [ Adam],\n",
    "     'losses': ['mean_squared_error'],\n",
    "     'activation':[elu,relu],\n",
    "     'last_activation': ['elu','relu']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Talos\n",
    "\n",
    "As we presented earlier, when designing the architecture for an artificial neural network, there exist a variety of parameters that can be tuned.\n",
    "\n",
    "Just like we have GridSearchCV for hyperparameter optimization within scikit-learn models like Decision Trees, Talos can be applied on Keras models. Talos works similarly to GridSearchCV, by testing all possible combinations of those parameters we have introduced, and chooses the best model, based on what parameter we have asked it to either optimize or reduce (MSE in our case).\n",
    "\n",
    "Optimize or reduce performed by cross validation K-fold method. As mentioned earlier, that's the reason why we didn't split the data to validation set and just used training set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: train set, model settings, hyperparamaters grid\n",
    "#output: csv file with all combinations.\n",
    "start = time.time()\n",
    "force_cpu()\n",
    "t = ta.Scan(x=X_train,\n",
    "            y=y_train,\n",
    "            model=model_opti,\n",
    "            params=p,\n",
    "            dataset_name='talos tutorial',\n",
    "            experiment_no='1',\n",
    "            reduction_metric=\"val_loss\", \n",
    "            reduce_loss=True)\n",
    "\n",
    "end = time.time()\n",
    "during=end - start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training time is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(during/3600)+\" hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to use the Reporting command to evaluate the experiments. Reporting saves a CSV-file where each experiment is stored with its results (talos tutorial_1.csv). In this file, you can see the rounds_epochs, val_loss, val_accuracy, train loss, test accuracy, activation function, and number of neurons for first and second hidden layer, the optimizer and loss function, batch size, and epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = ta.Reporting(t)\n",
    "#accessing the results data frame\n",
    "print(r.data.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By printing the best_params for val_loss, those experiments with the lowest loss value are visualized.\n",
    "In our case, the combination of the below: \n",
    "\n",
    "\n",
    "- First Neurons: 9 \n",
    "- Number of hidden layers: 3\n",
    "- Batch size: 128 \n",
    "- Epochs: We used a small number in order to get fast tune of the model. in the next section we will use larger number (11000).\n",
    "- Dropout: 0.6\n",
    "- Kernel initializer: normal\n",
    "- Optimizer: Adam \n",
    "- Loss function: MSE \n",
    "- Activation function : elu \n",
    "- Last activation function : relu \n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best paramaters\n",
    "print(r.best_params()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####   Selected model training\n",
    "\n",
    "Using the best hyperparameters with larger epoch number, in order to fine tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the parameter space\n",
    "p2 =  {'first_neuron':[9],\n",
    "     'hidden_layers':[3],\n",
    "     'batch_size': [128],\n",
    "     'epochs': [11000],\n",
    "     'dropout': [0.6],\n",
    "     'kernel_initializer': ['normal'],\n",
    "     'optimizer': [ Adam],\n",
    "     'losses': ['mean_squared_error'],\n",
    "     'activation':[elu],\n",
    "     'last_activation': ['relu']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: train set, model settings, hyperparamaters grid\n",
    "#output: csv file with final combination.\n",
    "start1 = time.time()\n",
    "force_cpu()\n",
    "t2 = ta.Scan(x=X_train,\n",
    "            y=y_train,\n",
    "            model=model_opti,\n",
    "            params=p2,\n",
    "            dataset_name='talos tutorial',\n",
    "            experiment_no='pred')\n",
    "end1 = time.time()\n",
    "during1=end1 - start1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuning time is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(during1/3600)+\" hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREDICTION\n",
    "We are ready now to Deploy the model.\n",
    "Finally, we used the SAE-FNN model in order to predict the test set.\n",
    "Deploy command prepares a zip-file that can be transferred to another environment or system. The zip files provide us the information about the experiment in “SAE1_results.csv”, the weights of the model, saved as “SAE1_model.h5, and the model in a json format: “SAE1_model.json”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta.Deploy(t2, 'SAE1')\n",
    "SAE1 = ta.Restore('SAE1.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have used the Deploy command, we can get access to the model and use it for Prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred=SAE1.model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predication results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_val = sqrt(mean_squared_error(y_test, pred))     #RMSEP\n",
    "r2_val = r2_score(y_test, pred)     #R2P\n",
    "RPDp=np.std(y_test)/rmse_val*1.0    #RPDp\n",
    "\n",
    "print(\" prediction r2 is: \" + str(r2_val))\n",
    "print(\" prediction rms error is: \" + str(rmse_val))\n",
    "print(\" prediction RPDp is: \" + str(RPDp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  SUMMARY AND CONCLUSION\n",
    "\n",
    "The results of this study demonstrate that deep learning model was feasible to be used as Hyperspectral imaging data analysis method for N prediction in oilseed rape leaf.\n",
    "\n",
    "In addition, Talos is a useful package for solving complex neural network models and deciding on the right combination of parameters. The best model can be generated by running the code one time, instead of after each change of a single parameter. This saves us time and makes it easier to find the best combinations with the lowest loss values.\n",
    "\n",
    "The results presented above may seem different. However, we still believe that SAE-FNN10 outperforms other algorithms on the types of data trained on, which is the primary conclusion made by the authors of the original paper. We believe that our recreation/extension shows non-similar results due to difference in random state and hyperparameters optimization method.\n",
    "\n",
    "#### PERFORMANCE MEASURES\n",
    "\n",
    "\n",
    "Quality of predictions given by the following measurements: \n",
    "\n",
    "$ RMSE(y,\\hat{y})=\\sqrt{\\frac{1}{n}\\sum_{i=0}^{n-1}(y_{i}-\\hat{y}_{i})^2} $ - A measure of the difference.\n",
    "\n",
    "$ R^2=(y,\\hat{y})=1-\\frac{\\sum_{i=1}^{n}(y_{i}-\\hat{y_{i}})^2}{\\sum_{i=1}^{n}(y_{i}-\\bar{y_{i}})^2} $ -Explained variance.\n",
    "\n",
    "$ RPDP=\\frac{S(y)}{RMSE} $ -Residual predictive deviations.\n",
    " \n",
    "#### The results (paper results):\n",
    "$ R^2 = 0.678 $ (Paper result: 0.903)\n",
    "\n",
    "$ Rmse = 0.039 $ (Paper result: 0.307)\n",
    "\n",
    "$ RPDp = 1.764 $ (Paper result: 3.238)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
